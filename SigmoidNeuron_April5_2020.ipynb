{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SigmoidNeuron_April5_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYvzqHNnxDoyD2hjh1c+0U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5c20b0a84cc74350a426450c18d2008c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_54dc64e1dcf94bc796c8c0fc61bdcf45",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_05ec0bf4a47b40bbbff9c2f4274732d3",
              "IPY_MODEL_5ee2317acb81473b89e1c372c77547ae"
            ]
          }
        },
        "54dc64e1dcf94bc796c8c0fc61bdcf45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05ec0bf4a47b40bbbff9c2f4274732d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4c5e4432a0d54ea2969f7576f14b8a0d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5500,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5500,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92a658e8be754b7fb1db6ba7252f3f50"
          }
        },
        "5ee2317acb81473b89e1c372c77547ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e23581243bae407fbb39bbf0df42b22d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5500/5500 [01:02&lt;00:00, 87.35epoch/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d93280a1b0c24487a87dfb86208f962b"
          }
        },
        "4c5e4432a0d54ea2969f7576f14b8a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92a658e8be754b7fb1db6ba7252f3f50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e23581243bae407fbb39bbf0df42b22d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d93280a1b0c24487a87dfb86208f962b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srinivasanibmbangalore/Deep-Learning2/blob/Version-1/SigmoidNeuron_April5_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj6FeeekHIFc",
        "colab_type": "text"
      },
      "source": [
        "**Data** : Mobile Data Set Shared by IIT Chennai Padhai - Mobile Dataset\n",
        "Task :\n",
        "Regression (Logistic Regression) - With thresholds, the probabilities can be converted to classification model as well (0 or 1)\n",
        "\n",
        "Model :\n",
        "Sigmoid Function It is actually a sigmoid logistic function.  ùëÜùë§,ùëè(ùë•) = 11+ùëí‚àí(ùë§ùë•+ùëè) \n",
        "\n",
        "Advantages: 1.Not a linear Function : So linear separability issue kind of is eliminated 2.A smooth function : 3.Differentiable 4.The parameters to learn are w, and b. 5.As w becomes more negative, slope increases. 6.As b decreases, boundary of the curve shifts to right.\n",
        "\n",
        "Loss Function:\n",
        "Mean Square Error\n",
        "\n",
        "Learning Algorithm:\n",
        "Gradient Descent\n",
        "\n",
        "Accuracy Evaluation:\n",
        "Root Mean Square\n",
        "\n",
        "Intermediate Visualization :\n",
        "3D Projection Plots in Matplot with cmaps as virdis\n",
        "######## Sometimes the default viewing angle is not optimal, in which case we can use the view_init method to set the elevation and azimuthal angles. In the following example, we'll use an elevation of 60 degrees (that is, 60 degrees above the x-y plane) and an azimuth of 35 degrees (that is, rotated 35 degrees counter-clockwise about the z-axis):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc-s_efSG9S4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sklearn.datasets as ds #Very popular dataset\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from   mpl_toolkits import mplot3d # for plotting 3d plots\n",
        "import random as rn\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.colors\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSh9TV_0HsVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SigmoidNeuron:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.w=None\n",
        "        self.b=None\n",
        "    \n",
        "    def perceptron(self,x):\n",
        "        return np.dot(x,self.w.T)+self.b\n",
        "    \n",
        "    def sigmoid(self,x):\n",
        "        return 1.0/(1.0+ np.exp(-x))\n",
        "    \n",
        "    def predict(self,X):\n",
        "      Y_pred = []\n",
        "      for x in X:\n",
        "        y_pred=self.sigmoid(self.perceptron(x))\n",
        "        Y_pred.append(y_pred)\n",
        "      return np.array(Y_pred)\n",
        "\n",
        "    \n",
        "    def grad_w(self,x,y):\n",
        "        y_pred=self.sigmoid(self.perceptron(x))\n",
        "        grd_w= (y_pred-y)*y_pred*(1-y_pred)*x\n",
        "        return grd_w\n",
        "    \n",
        "    def grad_b(self,x,y):\n",
        "        y_pred=self.sigmoid(self.perceptron(x))\n",
        "        grd_b= (y_pred-y)*y_pred*(1-y_pred)\n",
        "        return grd_b\n",
        "    \n",
        "    def fit(self,X,Y,epochs=1,lr=1,intialize=True,display_loss=False):\n",
        "\n",
        "        if (intialize):\n",
        "            self.w = np.random.randn(1,X.shape[1]) ## W is initialized. It contains the same row as number of columns in X\n",
        "            self.b=0\n",
        "        if (display_loss):\n",
        "          loss=[] #initialize a loss dictionary\n",
        "        for i in tqdm_notebook(range(epochs), total=epochs,unit=\"epoch\"):\n",
        "            dw=0\n",
        "            db=0\n",
        "            for x, y in zip(X,Y):\n",
        "                dw = dw+self.grad_w(x,y)\n",
        "                db = db+self.grad_b(x,y)\n",
        "            self.w=self.w-lr*dw\n",
        "            self.b=self.b-lr*db\n",
        "            Y_pred=self.sigmoid(self.perceptron(X))\n",
        "            if (display_loss):\n",
        "                loss.append(mean_squared_error(Y_pred,Y))\n",
        "                #print(loss[i])\n",
        "        print(\"Epochs is \",i)\n",
        "        if (display_loss):\n",
        "            plt.plot(loss)\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('Mean Squared Error loss')\n",
        "            plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWgQbpI2KTNA",
        "colab_type": "text"
      },
      "source": [
        "#### Get the data and store in google drive\n",
        "\n",
        "The dummy data on like/dislike of phone is provided by PadhiAI( IIT Chennai)\n",
        "The file is stored in Srini's mobile drive. The shareable link of the same is \n",
        "https://drive.google.com/open?id=1OqjyyMZ5kWcOnq1lJkPHmfiJ5CbqKNwl\n",
        "\n",
        "Below is a snippet of code provided by Google Colab to read data from a Google drive\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnXFHMcmKRvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eJRUekypPDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shareable_link=\"https://drive.google.com/open?id=1OqjyyMZ5kWcOnq1lJkPHmfiJ5CbqKNwl\"\n",
        "myfile = drive.CreateFile({'id': '1OqjyyMZ5kWcOnq1lJkPHmfiJ5CbqKNwl'})\n",
        "myfile.GetContentFile('file.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Faq5xSnqkR7",
        "colab_type": "code",
        "outputId": "c7e6cea2-b460-4574-e4c2-e2225f46ca58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "data=pd.read_csv(\"file.csv\")\n",
        "data.head()\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhoneId</th>\n",
              "      <th>Pixel Density</th>\n",
              "      <th>Screen Size</th>\n",
              "      <th>Weight</th>\n",
              "      <th>RAM</th>\n",
              "      <th>Processor_frequency</th>\n",
              "      <th>Screen to Body Ratio (calculated)</th>\n",
              "      <th>Height</th>\n",
              "      <th>Internal Memory</th>\n",
              "      <th>Capacity</th>\n",
              "      <th>Resolution</th>\n",
              "      <th>SIM 2_2G</th>\n",
              "      <th>SIM 2_3G</th>\n",
              "      <th>SIM 2_4G</th>\n",
              "      <th>SIM 2_Other</th>\n",
              "      <th>Num_cores_312</th>\n",
              "      <th>Num_cores_Deca</th>\n",
              "      <th>Num_cores_Dual</th>\n",
              "      <th>Num_cores_Hexa</th>\n",
              "      <th>Num_cores_Octa</th>\n",
              "      <th>Num_cores_Other</th>\n",
              "      <th>Num_cores_Quad</th>\n",
              "      <th>Num_cores_Tru-Octa</th>\n",
              "      <th>Brand_10.or</th>\n",
              "      <th>Brand_Apple</th>\n",
              "      <th>Brand_Asus</th>\n",
              "      <th>Brand_Billion</th>\n",
              "      <th>Brand_Blackberry</th>\n",
              "      <th>Brand_Comio</th>\n",
              "      <th>Brand_Coolpad</th>\n",
              "      <th>Brand_Do</th>\n",
              "      <th>Brand_Gionee</th>\n",
              "      <th>Brand_Google</th>\n",
              "      <th>Brand_HTC</th>\n",
              "      <th>Brand_Honor</th>\n",
              "      <th>Brand_Huawei</th>\n",
              "      <th>Brand_InFocus</th>\n",
              "      <th>Brand_Infinix</th>\n",
              "      <th>Brand_Intex</th>\n",
              "      <th>Brand_Itel</th>\n",
              "      <th>...</th>\n",
              "      <th>Brand_Meizu</th>\n",
              "      <th>Brand_Micromax</th>\n",
              "      <th>Brand_Mobiistar</th>\n",
              "      <th>Brand_Moto</th>\n",
              "      <th>Brand_Motorola</th>\n",
              "      <th>Brand_Nokia</th>\n",
              "      <th>Brand_Nubia</th>\n",
              "      <th>Brand_OPPO</th>\n",
              "      <th>Brand_OnePlus</th>\n",
              "      <th>Brand_Oppo</th>\n",
              "      <th>Brand_Panasonic</th>\n",
              "      <th>Brand_Razer</th>\n",
              "      <th>Brand_Realme</th>\n",
              "      <th>Brand_Reliance</th>\n",
              "      <th>Brand_Samsung</th>\n",
              "      <th>Brand_Sony</th>\n",
              "      <th>Brand_Spice</th>\n",
              "      <th>Brand_Tecno</th>\n",
              "      <th>Brand_Ulefone</th>\n",
              "      <th>Brand_VOTO</th>\n",
              "      <th>Brand_Vivo</th>\n",
              "      <th>Brand_Xiaomi</th>\n",
              "      <th>Brand_Xiaomi Poco</th>\n",
              "      <th>Brand_Yu</th>\n",
              "      <th>Brand_iVooMi</th>\n",
              "      <th>os_name_Android</th>\n",
              "      <th>os_name_Blackberry</th>\n",
              "      <th>os_name_KAI</th>\n",
              "      <th>os_name_Nokia</th>\n",
              "      <th>os_name_Other</th>\n",
              "      <th>os_name_Tizen</th>\n",
              "      <th>os_name_iOS</th>\n",
              "      <th>SIM Slot(s)_Dual SIM, GSM+CDMA</th>\n",
              "      <th>SIM Slot(s)_Dual SIM, GSM+GSM</th>\n",
              "      <th>SIM Slot(s)_Dual SIM, GSM+GSM, Dual VoLTE</th>\n",
              "      <th>SIM Slot(s)_Single SIM, GSM</th>\n",
              "      <th>Sim1_2G</th>\n",
              "      <th>Sim1_3G</th>\n",
              "      <th>Sim1_4G</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>403</td>\n",
              "      <td>6.26</td>\n",
              "      <td>182</td>\n",
              "      <td>4</td>\n",
              "      <td>1.8</td>\n",
              "      <td>80.68</td>\n",
              "      <td>157.9</td>\n",
              "      <td>64</td>\n",
              "      <td>4000</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>271</td>\n",
              "      <td>6.20</td>\n",
              "      <td>168</td>\n",
              "      <td>3</td>\n",
              "      <td>1.8</td>\n",
              "      <td>80.85</td>\n",
              "      <td>156.2</td>\n",
              "      <td>32</td>\n",
              "      <td>4230</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>409</td>\n",
              "      <td>6.30</td>\n",
              "      <td>168</td>\n",
              "      <td>3</td>\n",
              "      <td>2.1</td>\n",
              "      <td>83.68</td>\n",
              "      <td>157.0</td>\n",
              "      <td>32</td>\n",
              "      <td>3500</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>411</td>\n",
              "      <td>6.00</td>\n",
              "      <td>169</td>\n",
              "      <td>4</td>\n",
              "      <td>2.2</td>\n",
              "      <td>74.78</td>\n",
              "      <td>159.8</td>\n",
              "      <td>64</td>\n",
              "      <td>3300</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>396</td>\n",
              "      <td>6.50</td>\n",
              "      <td>175</td>\n",
              "      <td>4</td>\n",
              "      <td>2.2</td>\n",
              "      <td>84.23</td>\n",
              "      <td>160.4</td>\n",
              "      <td>64</td>\n",
              "      <td>3750</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 88 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhoneId  Pixel Density  Screen Size  ...  Sim1_3G  Sim1_4G  Rating\n",
              "0        0            403         6.26  ...        0        1     4.5\n",
              "1        1            271         6.20  ...        0        1     4.5\n",
              "2        2            409         6.30  ...        0        1     4.4\n",
              "3        4            411         6.00  ...        0        1     4.3\n",
              "4        5            396         6.50  ...        0        1     4.4\n",
              "\n",
              "[5 rows x 88 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYVOcLLktkXy",
        "colab_type": "code",
        "outputId": "4d496bb5-8735-46b0-f03b-b6872a2fe37b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(341, 88)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZNM5Up_t8P_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=data.drop('Rating',axis=1) # Drop the last column . This is the class label 'Rating\n",
        "Y=data['Rating'].values # Y is the last column only. i.e with 'Rating' only\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5CDzBs7vMHA",
        "colab_type": "text"
      },
      "source": [
        "#### An important thing to note is that X is allways maintained as a data frame since it contains rows and columns\n",
        "***Y is converted from a Dataframe to a Numpy Array since it is allways easier to manage and process.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2vRPSlJzMAB",
        "colab_type": "text"
      },
      "source": [
        "###### There is a need for maintaining both a binarized version of 'Y' as well as real valued value of Y since ***we*** are kind of doing binary classification\n",
        "\n",
        "***So train the data on actual value of Y , compute the accuracy of the model using binarized value of Y***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFGuFpSm0Y4O",
        "colab_type": "text"
      },
      "source": [
        "##### So it is important to look at the values of Y closely, define. the threshold and binarize it. \n",
        "\n",
        "#### Introduce a new column in the original data frame with an additional column 'Class' to hold the binarized rating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mddd0Ij6vgRv",
        "colab_type": "code",
        "outputId": "573a35c7-60da-483b-f678-7fed7ab11b46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "threshold = 4.0\n",
        "data['Class']=(data['Rating'] >= threshold).astype(np.int) # convert to integer as store the value\n",
        "data['Class'].value_counts()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    238\n",
              "0    103\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyymXVks2FQM",
        "colab_type": "text"
      },
      "source": [
        "#### Observation of the value counts, we see that class is kind of skewed\n",
        "#### We will readjust the value of threshoulds and run it again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9Hpycjj2Ziw",
        "colab_type": "code",
        "outputId": "ebc5408d-891e-409f-8a44-e19289ae3fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "threshold = 4.2\n",
        "data['Class']=(data['Rating'] >= threshold).astype(np.int) # convert to integer as store the value\n",
        "data['Class'].value_counts(normalize=True) # normalize = True helps in looking at % value of the split"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.533724\n",
              "1    0.466276\n",
              "Name: Class, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-098Zg5H3KfL",
        "colab_type": "text"
      },
      "source": [
        "##### So at threshold=4.2, we get 53% '1' value and 47% 0 value "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKVKINlF35ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_binarized = data['Class'].values # Binarized values in a numpy array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCK7zFez70Mu",
        "colab_type": "text"
      },
      "source": [
        "#### ***Standardization of data is the next key step***\n",
        "To center the data (make it have zero mean and unit standard error), you subtract the mean and then divide the result by the standard deviation.\n",
        "\n",
        "$ùë•‚Ä≤$=$\\frac{ùë•‚àíùúá}{ùúé}$\n",
        "\n",
        "This is where you use the sklearn.preprocessor fit and fit transform methods.\n",
        "\n",
        "You do that on the training set of data. But then you have to apply the same transformation to your testing set (e.g. in cross-validation), or to newly obtained examples before forecast. But you have to use the same two parameters ùúá and ùúé (values) that you used for centering the training set.\n",
        "\n",
        "Hence, every sklearn's transform's fit() just calculates the parameters (e.g. ùúá and ùúé in case of StandardScaler) and saves them as an internal objects state. Afterwards, you can call its transform() method to apply the transformation to a particular set of examples.\n",
        "\n",
        "fit_transform() joins these two steps and is used for the initial fitting of parameters on the training set ùë•, but it also returns a transformed ùë•‚Ä≤. Internally, it just calls first fit() and then transform() on the same data.\n",
        "\n",
        "So we use the 'Standard Scaler' of sklearn preprocessor. \n",
        "The StandardScaler assumes your data is normally distributed within each feature and will scale them such that the distribution is now centred around 0, with a standard deviation of 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcZyPqWula7N",
        "colab_type": "text"
      },
      "source": [
        "### ***You should split the data between training and test data and then only standardize***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQP4H-4FmDqv",
        "colab_type": "code",
        "outputId": "019c5053-212c-460a-dafb-049c417d5c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,random_state=1,stratify=Y_binarized) # setting random_state ensures every time the code is run, results are same\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(255, 87) (86, 87)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch7A1YITnilC",
        "colab_type": "text"
      },
      "source": [
        "######### In real life, you have access to only the training data. We use fit_transform() on the train data so that we learn the parameters of scaling on the train data and in the same time we scale the train data. We only use transform() on the test data because we use the scaling paramaters learned on the train data to scale the test data. i.e apply the same mean and standard deviation learnt on the training data to the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V53HTG3hpVjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Scaler = StandardScaler()\n",
        "X_scaled_train = Scaler.fit_transform(X_train)\n",
        "X_scaled_test = Scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9I2ayIRr2_E",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIGBUkqqqlc0",
        "colab_type": "text"
      },
      "source": [
        "####### Y Variables need to be transformed in a different manner. Y varies from 0 to 1. It is a sigmoid function. So we need to use a different scaler. The trick is min has to be zero and max has to be 1. So the sklearn preprocessor is 'MinMax Scaler'.\n",
        "The concept of fit_transform() and transform() all apply to MinMax Scaler also."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpzKnWGerVLt",
        "colab_type": "code",
        "outputId": "e3c874d6-3008-4598-98bd-6bb54e853739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "minmax_scaler = MinMaxScaler()\n",
        "Y_scaled_train = minmax_scaler.fit_transform(Y_train.reshape(-1,1))\n",
        "Y_scaled_test = minmax_scaler.transform(Y_test.reshape(-1,1))\n",
        "print(np.max(Y_scaled_train),np.min(Y_scaled_train))\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2YgIhE003zk",
        "colab_type": "text"
      },
      "source": [
        "###### We need to do the same for the binarized data as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uacUldd22TyG",
        "colab_type": "code",
        "outputId": "938226ac-f5ae-4983-f719-fb560b040759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scaled_threshold = list(minmax_scaler.transform(np.array([threshold]).reshape(1,-1)))[0][0]\n",
        "print(scaled_threshold)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6800000000000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sULvok7nEX3D",
        "colab_type": "text"
      },
      "source": [
        "########The criterion to satisfy for providing the new shape is that 'The new shape should be compatible with the original shape'\n",
        "\n",
        "numpy allow us to give one of new shape parameter as -1 (eg: (2,-1) or (-1,3) but not (-1, -1)). It simply means that it is an unknown dimension and we want numpy to figure it out. And numpy will figure this by looking at the 'length of the array and remaining dimensions' and making sure it satisfies the above mentioned criteria\n",
        "\n",
        "numpy.ndarray.flatten function returns a copy of an array collapsed into one dimension. The function takes the following parameters.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "a = np.arange(10)\n",
        "print(\"Original array : \\n\", a)\n",
        "\n",
        "a = np.arange(10).reshape(2, 5)\n",
        "\n",
        "print(\"printing 2 * 5 dimentional array\",a)\n",
        "\n",
        "b= a.flatten()\n",
        "\n",
        "print(\"printing Flattern array using flatten() function\",b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ogbv3FEr3gc7",
        "colab_type": "text"
      },
      "source": [
        "###### So 4.2 which was the threshold has now become 0.68 as the threshold in the binarized world."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP1ZbmT_3plf",
        "colab_type": "code",
        "outputId": "987f57c3-553a-477f-eedb-c872100a0147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "Y_binarized_train = (Y_scaled_train >= scaled_threshold).astype(np.int).ravel()\n",
        "print(Y_binarized_train)\n",
        "Y_binarized_test = (Y_scaled_test >= scaled_threshold).astype(np.int).ravel()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1\n",
            " 1 0 1 0 0 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 0 0 0 0 1 1\n",
            " 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1\n",
            " 0 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0\n",
            " 0 1 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 1 0\n",
            " 1 1 1 0 1 1 0 0 0 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-pGLHPk0Im2",
        "colab_type": "text"
      },
      "source": [
        "#### Actual Fitment of Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S--aP9WM0HBC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383,
          "referenced_widgets": [
            "5c20b0a84cc74350a426450c18d2008c",
            "54dc64e1dcf94bc796c8c0fc61bdcf45",
            "05ec0bf4a47b40bbbff9c2f4274732d3",
            "5ee2317acb81473b89e1c372c77547ae",
            "4c5e4432a0d54ea2969f7576f14b8a0d",
            "92a658e8be754b7fb1db6ba7252f3f50",
            "e23581243bae407fbb39bbf0df42b22d",
            "d93280a1b0c24487a87dfb86208f962b"
          ]
        },
        "outputId": "38844f82-5a89-4cc8-b8bf-4f2815316f29"
      },
      "source": [
        "sn = SigmoidNeuron()\n",
        "sn.fit(X_scaled_train,Y_scaled_train,epochs=5500,lr=0.01,display_loss=True)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c20b0a84cc74350a426450c18d2008c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5500), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs is  5499\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imw7lJnCdLJO",
        "colab_type": "text"
      },
      "source": [
        "#### The above is called the loss plot. \n",
        "### Large Drop in initial iterations. Changng the hyper parameter and modifying the lr and epoch is key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHebJaY4N_M1",
        "colab_type": "text"
      },
      "source": [
        "####### Predict for the training and test data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u3KtXEEOGgm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred_train=sn.predict(X_scaled_train)\n",
        "Y_pred_test=sn.predict(X_scaled_test)\n",
        "\n",
        "Y_pred_binarized_train= (Y_pred_train >= scaled_threshold).astype(\"int\").ravel()\n",
        "Y_pred_binarized_test= (Y_pred_test >= scaled_threshold).astype(\"int\").ravel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhvffb9UPf8_",
        "colab_type": "text"
      },
      "source": [
        "##### Accuracy Score Computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79j8Igr-Pl4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e720e6b9-c79b-4166-8c82-e5a6de8d2c5c"
      },
      "source": [
        "accuracy_train = accuracy_score(Y_pred_binarized_train,Y_binarized_train)\n",
        "accuracy_test = accuracy_score(Y_pred_binarized_test,Y_binarized_test)\n",
        "print(accuracy_train,accuracy_test)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7568627450980392 0.7093023255813954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivvWnd7TQE5i",
        "colab_type": "text"
      },
      "source": [
        "###### Change the epoch and learning rate in sn.fit and see how it improves the Test and Training Accuracy. At an epoch of 2500 and learning rate of 0.02 we attain a relatively high accuracy in training and testing data set "
      ]
    }
  ]
}
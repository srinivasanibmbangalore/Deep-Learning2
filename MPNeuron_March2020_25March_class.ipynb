{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MPNeuron_March2020_25March_class.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOfAtzI5xobe9m5PjDlWHHg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srinivasanibmbangalore/Deep-Learning2/blob/master/MPNeuron_March2020_25March_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djQfTuB34uo7",
        "colab_type": "text"
      },
      "source": [
        "The objective of this code is to templatize the model writing as a class. The template may be used for other types of models including Perceptron, Sigmoid and other kinds of models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIEMWGH34AC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sklearn.datasets as ds #Very popular dataset\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random as rn\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwJNBmx549w0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MPNeuron:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.b = None\n",
        "  \n",
        "  #This is the model function for MP Neuron. For an MP Neuron, the function evaluates if sum of the binarized feature vectors\n",
        "  #is greater or lesser than one.\n",
        "\n",
        "  def model(self, X):\n",
        "    return( sum(X) >= self.b )\n",
        "\n",
        "  def predict(self,X):\n",
        "    Y = []\n",
        "    for i in X:\n",
        "        result=self.model(i)\n",
        "        Y.append(result)\n",
        "    return np.array(Y)\n",
        "  \n",
        "  #This is the actual learning algorithm. It takes in the Training Value of both X & Y\n",
        "  def fit(self,X,Y):\n",
        "    accuracy = {} #Define a dictionary for storing the accuracy\n",
        "\n",
        "    for b in range(X.shape[1]+1):\n",
        "      self.b = b\n",
        "      Y_pred=self.predict(X)\n",
        "      accuracy[b]=accuracy_score(Y_pred,Y)\n",
        "\n",
        "    best_b=max(accuracy,key=accuracy.get)\n",
        "   \n",
        "    self.b=best_b\n",
        "    print(\"best value of b is \",self.b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5ehgyxlkQN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MPNeuron_DataPreparation:\n",
        "  def __init__(self):\n",
        "    self.data = None\n",
        "    self.X = None\n",
        "    self.Y = None\n",
        "    self.X_binarized_test_numpy=None\n",
        "    self.X_binarized_train_numpy=None\n",
        "    self.Y_train=None\n",
        "    self.Y_test=None\n",
        "\n",
        "  def load_bc_dataset(self):\n",
        "    bc=ds.load_breast_cancer()\n",
        "    data=pd.DataFrame(bc.data,columns=bc.feature_names)\n",
        "    data['class']=bc.target\n",
        "    self.data = data\n",
        "  \n",
        "  def print_data_header(self):\n",
        "    data=self.data\n",
        "    data.head()\n",
        "    data.describe()\n",
        "    data['class'].value_counts()\n",
        "    #print(data.columns)\n",
        "    data.groupby('class').mean()\n",
        "\n",
        "  def prepare_data(self):\n",
        "     data=self.data\n",
        "     self.X=data.drop('class', axis=1) # The class label is dropped and stored in a separate array\n",
        "     self.Y=data['class'] # The class label array is stored separately\n",
        "\n",
        "\n",
        "  def plotValues(self,X):\n",
        "    plt.plot(X.T,'*')\n",
        "    plt.xticks(rotation='vertical')\n",
        "    plt.show()\n",
        "\n",
        "  def split_train_test_data_and_binarize (self,X,Y):\n",
        "    \n",
        "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.1,stratify=Y,random_state=1) #10% test and 90% Training\n",
        "    self.Y_train=Y_train\n",
        "    self.Y_test=Y.test\n",
        "    print(Y_train.mean())\n",
        "    self.plotValues(X_train)\n",
        "\n",
        "    X_binarized_train=X_train.apply(pd.cut,bins=2,labels=[1,0]) ### Remember the label values for binning. It needs to be iterated accordingly\n",
        "    self.plotValues(X_binarized_train)\n",
        "\n",
        "    X_binarized_test=X_test.apply(pd.cut,bins=2,labels=[1,0])\n",
        "    self.plotValues(X_binarized_test)\n",
        "    \n",
        "    self.X_binarized_test_numpy=X_binarized_test.values\n",
        "    self.X_binarized_train_numpy=X_binarized_train.values\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhHDv00rtn9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}